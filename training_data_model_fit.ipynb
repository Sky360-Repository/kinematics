{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8325b43b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "from scipy.spatial import distance\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utility import *\n",
    "from direction_change_distances import direction_change_distances\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sktime.classification.hybrid import HIVECOTEV2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4691c376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from matplotlib.font_manager import json_load\n",
    "#import sys\n",
    "#stdout = sys.stdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "d373b85d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished\n"
     ]
    }
   ],
   "source": [
    "# Read in csv file with video meta data\n",
    "# each row needs to have following info: file path, video number, object, track\n",
    "video_files = pd.read_csv('E:\\\\Sky360_videos\\\\video_files.csv')\n",
    "print(\"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f8d919a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run complete\n"
     ]
    }
   ],
   "source": [
    "\"\"\"Run this cell for each object and attach numbers to dist_list,direction_change_list_cleaned and y_in accordingly. These \n",
    "lists are concatenated in the next cell.\"\"\"\n",
    "\n",
    "Object = \"Plane\" # Plane or Bird or Plant\n",
    "sequence_length = 30 # Sequence length to train on\n",
    "\n",
    "\"\"\"For a given object get a list of distances [px] and direction changes [°] calculated between consecutive images. This\n",
    "will produce a warning for instances when the magnitude of a direction vector is 0. Will be dealt with in the following\n",
    "lines.\"\"\"\n",
    "dist_list,direction_change_list = direction_change_distances(video_files,Object,sequence_length)\n",
    "\n",
    "## Concatenation of input variables\n",
    "\n",
    "\"\"\"direction_change_list contains NaNs here and there for the instances described above. Here it makes sense to just\n",
    "replace nans with 0.\"\"\"\n",
    "direction_change_list_cleaned = clean_nans(direction_change_list)\n",
    "\n",
    "# these are the object labels for model training\n",
    "y_in = np.array([Object for _ in range(int(len(dist_list)/sequence_length))], dtype='<U9')\n",
    "\n",
    "# little test if input training data and labels have equal lengths\n",
    "len(dist_list)/sequence_length == len(y_in)\n",
    "print(\"run complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6a2bfc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"concatenate model input data (dist_list, direction_change_list_cleaned) of different objects\"\"\" \n",
    "\n",
    "# input for model training\n",
    "dist_list_all = list(dist_list) + list(dist_list2) + list(dist_list3)\n",
    "direction_change_list_all = list(direction_change_list_cleaned) + list(direction_change_list_cleaned2) + list(direction_change_list_cleaned3)\n",
    "# labels for model training\n",
    "y = np.concatenate((y_in, y_in2,y_in3), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e79c89dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "152\n",
      "143\n",
      "160\n"
     ]
    }
   ],
   "source": [
    "print(len(y_in))\n",
    "print(len(y_in2))\n",
    "print(len(y_in3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "201aec58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare input dataframe needed for the model\n",
    "# First input variable: directional changes [px]\n",
    "d = {}\n",
    "n = 0\n",
    "for i in range(0,len(dist_list_all)):\n",
    "    if i % sequence_length == 0:\n",
    "      d[n] = pd.Series(direction_change_list_all[i:i+sequence_length])\n",
    "      n += 1\n",
    "df = pd.Series(d).to_frame('Direction_changes')\n",
    "\n",
    "# 2nd input variable: distances [°]\n",
    "d = {}\n",
    "n = 0\n",
    "for i in range(0,len(dist_list_all)):\n",
    "    if i % sequence_length == 0:\n",
    "      d[n] = pd.Series(dist_list_all[i:i+sequence_length])\n",
    "      n += 1\n",
    "df2 = pd.Series(d).to_frame('Distances')\n",
    "\n",
    "# Concatenate different input variables to one input dataframe\n",
    "X = pd.concat([df, df2], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ffe2f4ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "455.0\n",
      "455\n"
     ]
    }
   ],
   "source": [
    "# Little check: X.size divided by number of variables should equal y.size\n",
    "print(X.size/2)\n",
    "print(y.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7502d101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create datasets for training and testing\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a2563cc-0bb0-46ec-b814-603124e0dfce",
   "metadata": {},
   "source": [
    "Below the time series classification algo can be chosen, which will be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46158750",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the model\n",
    "# check following link for the multitude of available algos: \n",
    "# https://www.sktime.org/en/stable/api_reference/classification.html\n",
    "\n",
    "# here we just use the default values for now, has potential for improvements\n",
    "classifier = HIVECOTEV2(\n",
    "    stc_params={\"n_shapelet_samples\": 1000}, \n",
    "    drcif_params={\"n_estimators\": 25},\n",
    "    arsenal_params={\"n_estimators\": 10},\n",
    "    tde_params={\"n_parameter_samples\": 100},\n",
    "    verbose=0,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a6d17455-fbfd-4d7c-85ed-27238706ec90",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:808: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CNNClassifier(batch_size=4, n_epochs=20)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CNNClassifier</label><div class=\"sk-toggleable__content\"><pre>CNNClassifier(batch_size=4, n_epochs=20)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CNNClassifier(batch_size=4, n_epochs=20)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#CNN classifier\n",
    "from sktime.classification.deep_learning.cnn import CNNClassifier\n",
    "classifier = CNNClassifier(n_epochs=20,batch_size=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "8a1f7274-bcb6-4d9c-b927-6a00d1254a8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#FCN classifier\n",
    "from sktime.classification.deep_learning.fcn import FCNClassifier\n",
    "classifier = FCNClassifier(n_epochs=20,batch_size=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "888b7f7f-730c-46fe-aa01-3de893bc52ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MLP classifier\n",
    "from sktime.classification.deep_learning.mlp import MLPClassifier\n",
    "classifier = MLPClassifier(n_epochs=20,batch_size=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "ca7b5f2f-5fe7-4aeb-8c8e-94e4ebf553a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MUSE classifier\n",
    "from sktime.classification.dictionary_based import MUSE\n",
    "classifier = MUSE(window_inc=4, use_first_order_differences=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e1e6bb7d-2f7d-434f-a28a-c472c9d6880f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TemporalDictionaryEnsemble\n",
    "from sktime.classification.dictionary_based import TemporalDictionaryEnsemble\n",
    "classifier = TemporalDictionaryEnsemble(\n",
    "    n_parameter_samples=10,\n",
    "    max_ensemble_size=3,\n",
    "    randomly_selected_params=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b6f11cf3-cc21-4fbf-8e69-f2ba95b78c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNeighborsTimeSeries classifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "classifier = KNeighborsTimeSeriesClassifier(distance=\"euclidean\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "7fb94b25-f45f-4e43-9a0b-a233aeeece1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Catch22 classifier\n",
    "from sktime.classification.feature_based import Catch22Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = Catch22Classifier(\n",
    "    estimator=RandomForestClassifier(n_estimators=5),\n",
    "    outlier_norm=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a045566a-0f12-4b99-873b-c44388eec9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Summary classifier\n",
    "from sktime.classification.feature_based import SummaryClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "classifier = SummaryClassifier(estimator=RandomForestClassifier(n_estimators=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f3be1539-61eb-40f5-a75f-4f7aaf9e1e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CanonicalIntervalForest classifier\n",
    "from sktime.classification.interval_based import CanonicalIntervalForest\n",
    "classifier = CanonicalIntervalForest(\n",
    "    n_estimators=3, n_intervals=2, att_subsample_size=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "c56d13e1-9bc3-49fe-b92e-9c64d25d4302",
   "metadata": {},
   "outputs": [],
   "source": [
    "#DrCIF classifier\n",
    "from sktime.classification.interval_based import DrCIF\n",
    "classifier = DrCIF(n_estimators=3, n_intervals=2, att_subsample_size=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a1353df1-57c7-453e-92e9-c6b712c4bc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Arsenal classifier\n",
    "from sktime.classification.kernel_based import Arsenal\n",
    "classifier = Arsenal(num_kernels=100, n_estimators=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "93e751d0-56cb-49ef-a07e-25b9e76d678b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shapelet classifier\n",
    "from sktime.classification.shapelet_based import ShapeletTransformClassifier\n",
    "from sktime.classification.sklearn import RotationForest\n",
    "classifier = ShapeletTransformClassifier(\n",
    "    estimator=RotationForest(n_estimators=3),\n",
    "    n_shapelet_samples=100,\n",
    "    max_shapelets=10,\n",
    "    batch_size=20,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "b32c9292",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\datatypes\\_panel\\_convert.py:713: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for _label, _series in multi_ind_dataframe.iteritems():  # noqa\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Catch22Classifier(estimator=RandomForestClassifier(n_estimators=5),\n",
       "                  outlier_norm=True)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-22\" type=\"checkbox\" ><label for=\"sk-estimator-id-22\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Catch22Classifier</label><div class=\"sk-toggleable__content\"><pre>Catch22Classifier(estimator=RandomForestClassifier(n_estimators=5),\n",
       "                  outlier_norm=True)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-23\" type=\"checkbox\" ><label for=\"sk-estimator-id-23\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=5)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-24\" type=\"checkbox\" ><label for=\"sk-estimator-id-24\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=5)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Catch22Classifier(estimator=RandomForestClassifier(n_estimators=5),\n",
       "                  outlier_norm=True)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit model\n",
    "classifier.fit(X_train_tr, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "11a0629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternatively load model\n",
    "# import trained classification model\n",
    "with open('E:\\Dokumente\\Repos\\kinematics-main\\kinematics-main\\model_Catch22_bird_plant_plane_30.pkl', 'rb') as f:\n",
    "    clf = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "dc03eb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sktime\\datatypes\\_panel\\_convert.py:713: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for _label, _series in multi_ind_dataframe.iteritems():  # noqa\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Elapsed time is 1.627024 seconds.\n",
      "['Plant' 'Bird' 'Plant' 'Bird' 'Plant' 'Plane' 'Plant' 'Plane' 'Plane'\n",
      " 'Plant' 'Bird' 'Plant' 'Bird' 'Bird' 'Plane' 'Bird' 'Plant' 'Plant'\n",
      " 'Plane' 'Plane' 'Plant' 'Plant' 'Plant' 'Bird' 'Plane' 'Bird' 'Bird'\n",
      " 'Plane' 'Plane' 'Plane' 'Plant' 'Bird' 'Plane' 'Plant' 'Plane' 'Plant'\n",
      " 'Plane' 'Bird' 'Plant' 'Plant' 'Bird' 'Bird' 'Plant' 'Bird' 'Plane'\n",
      " 'Plane' 'Plant' 'Plant' 'Plane' 'Plane' 'Bird' 'Bird' 'Plane' 'Plant'\n",
      " 'Plane' 'Plant' 'Plane' 'Plant' 'Plant' 'Plant' 'Plant' 'Plane' 'Bird'\n",
      " 'Plane' 'Plant' 'Plane' 'Plant' 'Bird' 'Plant' 'Plane' 'Bird' 'Bird'\n",
      " 'Plant' 'Plant' 'Plant' 'Plant' 'Bird' 'Plant' 'Bird' 'Plant' 'Bird'\n",
      " 'Plant' 'Plane' 'Plane' 'Bird' 'Plane' 'Plane' 'Plant' 'Bird' 'Bird'\n",
      " 'Plant' 'Plane' 'Plane' 'Plane' 'Bird' 'Plane' 'Plant' 'Plane' 'Bird'\n",
      " 'Plant' 'Bird' 'Bird' 'Plant' 'Plane' 'Bird' 'Plane' 'Bird' 'Plane'\n",
      " 'Bird' 'Plant' 'Bird' 'Plane' 'Bird' 'Bird']\n",
      "['Plant' 'Bird' 'Plant' 'Bird' 'Plant' 'Plane' 'Plant' 'Plane' 'Plane'\n",
      " 'Plant' 'Bird' 'Plant' 'Bird' 'Bird' 'Plane' 'Plane' 'Plant' 'Plant'\n",
      " 'Plane' 'Plane' 'Plant' 'Plant' 'Plant' 'Bird' 'Plane' 'Plane' 'Plane'\n",
      " 'Plane' 'Plane' 'Plane' 'Plant' 'Bird' 'Plane' 'Plant' 'Plane' 'Plant'\n",
      " 'Plane' 'Bird' 'Plant' 'Plant' 'Bird' 'Bird' 'Plant' 'Bird' 'Plane'\n",
      " 'Plane' 'Plant' 'Plant' 'Plane' 'Plane' 'Bird' 'Bird' 'Plane' 'Plant'\n",
      " 'Plane' 'Plant' 'Bird' 'Plant' 'Plant' 'Plant' 'Bird' 'Plane' 'Bird'\n",
      " 'Plane' 'Plant' 'Bird' 'Plant' 'Bird' 'Plant' 'Plane' 'Bird' 'Bird'\n",
      " 'Plant' 'Plant' 'Plant' 'Plant' 'Bird' 'Plant' 'Bird' 'Plant' 'Bird'\n",
      " 'Plant' 'Plane' 'Plane' 'Bird' 'Plane' 'Bird' 'Plant' 'Bird' 'Plane'\n",
      " 'Plant' 'Plane' 'Plane' 'Plane' 'Bird' 'Plane' 'Plant' 'Plane' 'Bird'\n",
      " 'Plant' 'Bird' 'Bird' 'Plant' 'Plane' 'Bird' 'Plane' 'Bird' 'Plane'\n",
      " 'Bird' 'Plant' 'Plane' 'Plane' 'Bird' 'Bird']\n",
      "0.9210526315789473\n"
     ]
    }
   ],
   "source": [
    "# test the trained model\n",
    "from pytictoc import TicToc\n",
    "t = TicToc() #create instance of class\n",
    "\n",
    "#sys.stdout = stdout\n",
    "t.tic() #Start timer\n",
    "y_pred = clf.predict(X_test)\n",
    "t.toc() #Time elapsed since t.tic()\n",
    "\n",
    "print(y_pred)\n",
    "print(y_test)\n",
    "#y_pred_proba = classifier.predict_proba(X_test)\n",
    "score = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(score)\n",
    "#print(y_pred_proba)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "0e2b6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "with open('E:\\Dokumente\\Repos\\kinematics-main\\kinematics-main\\model_Catch22_bird_plant_plane_30.pkl','wb') as f:\n",
    "    pickle.dump(classifier,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "5baaafea-1f1b-4b0b-ac9c-6e6460535d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<zipfile.ZipFile filename='E:\\\\Dokumente\\\\Repos\\\\kinematics-main\\\\kinematics-main\\\\model_C22_bird_plant_plane_30.zip' mode='r'>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# not yet figured out how to reload models that are stored this way\n",
    "classifier.save(\"E:\\Dokumente\\Repos\\kinematics-main\\kinematics-main\\model_C22_bird_plant_plane_30\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2280f157-84dc-4ecc-bf52-2abe4e817ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "8c3d4d9970fc5c09c50d9318a9c7fbf4d0159e4b28833276f5678ee22bded273"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
